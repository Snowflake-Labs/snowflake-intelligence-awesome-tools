{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "init"
   },
   "outputs": [],
   "source": [
    "### \n",
    "### IMPORT THIS NOTEBOOK INTO A SNOWFLAKE NOTEBOOK AND RUN ALL CELLS\n",
    "###\n",
    "\n",
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cede5-3583-44e2-bbda-fdd9b6384691",
   "metadata": {
    "language": "sql",
    "name": "create_stage_for_procedure"
   },
   "outputs": [],
   "source": [
    "create stage if not exists awesome_tools;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a1bda-b71d-4a53-a7cb-b40b9ae2fbe8",
   "metadata": {
    "language": "sql",
    "name": "enable_cross_region"
   },
   "outputs": [],
   "source": [
    "-- optional - can replace with your region - this gives access to claude 4 and better performing models\n",
    "-- ALTER ACCOUNT SET CORTEX_ENABLED_CROSS_REGION = 'AWS_US';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee918bba-5851-4cab-a64a-65d3cb931f27",
   "metadata": {
    "language": "python",
    "name": "set_model"
   },
   "outputs": [],
   "source": [
    "# claude 4 requires cross region inference\n",
    "# potentially may want to use gpt-4.1 depending on your region / cloud\n",
    "model_for_generation = 'claude-4-sonnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b1ddf-4263-426f-aeaa-303c2e32daf6",
   "metadata": {
    "language": "python",
    "name": "create_streamlit_procedure"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Snowpark Python Stored Procedure to generate Streamlit apps using Snowflake Cortex Complete API\n",
    "\"\"\"\n",
    "\n",
    "import snowflake.snowpark as snowpark\n",
    "from snowflake.snowpark.functions import col, sproc\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "\n",
    "def strip_markdown_code_markers(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Strip markdown code markers from the beginning and end of the code if they exist.\n",
    "\n",
    "    Args:\n",
    "        code: The code string that might contain markdown markers\n",
    "\n",
    "    Returns:\n",
    "        str: Code with markdown markers removed\n",
    "    \"\"\"\n",
    "    # Strip whitespace\n",
    "    code = code.strip()\n",
    "\n",
    "    # Check for markdown code block markers\n",
    "    if code.startswith(\"```python\") or code.startswith(\"```\"):\n",
    "        # Find the first newline after the opening markers\n",
    "        first_newline = code.find(\"\\n\")\n",
    "        if first_newline != -1:\n",
    "            code = code[first_newline + 1 :]\n",
    "\n",
    "    # Remove closing markdown markers\n",
    "    if code.endswith(\"```\"):\n",
    "        # Find the last occurrence of ```\n",
    "        last_markers = code.rfind(\"```\")\n",
    "        if last_markers != -1:\n",
    "            code = code[:last_markers]\n",
    "\n",
    "    # Strip any remaining whitespace\n",
    "    return code.strip()\n",
    "\n",
    "\n",
    "def upload_code_to_stage(\n",
    "    session: snowpark.Session,\n",
    "    stage_name: str,\n",
    "    code: str,\n",
    "    filename: str = \"streamlit_app.py\",\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Helper function to upload generated code to a Snowflake stage\n",
    "\n",
    "    Args:\n",
    "        session: Snowpark session\n",
    "        stage_name: Name of the stage to upload to\n",
    "        code: The Python code to upload\n",
    "        filename: Name of the file to create\n",
    "\n",
    "    Returns:\n",
    "        bool: True if upload was successful, False otherwise\n",
    "    \"\"\"\n",
    "    temp_files = []\n",
    "    try:\n",
    "        # Create a temporary file with the generated code\n",
    "        with tempfile.NamedTemporaryFile(\n",
    "            mode=\"w\", suffix=\".py\", delete=False\n",
    "        ) as temp_file:\n",
    "            temp_file.write(code)\n",
    "            temp_file_path = temp_file.name\n",
    "\n",
    "        # Rename the temp file to the desired filename before uploading\n",
    "        target_path = os.path.join(os.path.dirname(temp_file_path), filename)\n",
    "        os.rename(temp_file_path, target_path)\n",
    "        temp_files.append(target_path)\n",
    "\n",
    "        # Create environment.yml file\n",
    "        environment_yml_content = \"\"\"name: sf_env\n",
    "channels:\n",
    "- snowflake\n",
    "dependencies:\n",
    "- plotly\n",
    "- altair\n",
    "\"\"\"\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(\n",
    "            mode=\"w\", suffix=\".yml\", delete=False\n",
    "        ) as env_temp_file:\n",
    "            env_temp_file.write(environment_yml_content)\n",
    "            env_temp_file_path = env_temp_file.name\n",
    "\n",
    "        # Rename the environment temp file\n",
    "        env_target_path = os.path.join(\n",
    "            os.path.dirname(env_temp_file_path), \"environment.yml\"\n",
    "        )\n",
    "        os.rename(env_temp_file_path, env_target_path)\n",
    "        temp_files.append(env_target_path)\n",
    "\n",
    "        # Upload the main Python file\n",
    "        put_result = session.file.put(\n",
    "            local_file_name=target_path,\n",
    "            stage_location=f\"@{stage_name}\",\n",
    "            auto_compress=False,\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "        # Upload the environment.yml file\n",
    "        env_put_result = session.file.put(\n",
    "            local_file_name=env_target_path,\n",
    "            stage_location=f\"@{stage_name}\",\n",
    "            auto_compress=False,\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "        # Clean up temporary files\n",
    "        for temp_file in temp_files:\n",
    "            os.unlink(temp_file)\n",
    "\n",
    "        # Check if both uploads were successful\n",
    "        main_upload_success = len(put_result) > 0 and put_result[0].status == \"UPLOADED\"\n",
    "        env_upload_success = (\n",
    "            len(env_put_result) > 0 and env_put_result[0].status == \"UPLOADED\"\n",
    "        )\n",
    "\n",
    "        return main_upload_success and env_upload_success\n",
    "\n",
    "    except Exception as e:\n",
    "        # Clean up temporary files if they exist\n",
    "        for temp_file in temp_files:\n",
    "            try:\n",
    "                os.unlink(temp_file)\n",
    "            except:\n",
    "                pass\n",
    "        return False\n",
    "\n",
    "\n",
    "@sproc(name=\"generate_streamlit\",\n",
    "       is_permanent=True,\n",
    "       stage_location=\"@awesome_tools\",\n",
    "       replace=True,\n",
    "       packages = [\"snowflake-snowpark-python\", \"snowflake-ml-python\"])\n",
    "def generate_streamlit_app(session: snowpark.Session, content: str) -> str:\n",
    "    \"\"\"\n",
    "    Snowpark stored procedure that calls Snowflake Cortex Complete API to generate a Streamlit app\n",
    "    based on the provided content.\n",
    "\n",
    "    Args:\n",
    "        session: Snowpark session\n",
    "        content: Long string containing the content/requirements for the Streamlit app\n",
    "\n",
    "    Returns:\n",
    "        JSON string containing the generated Streamlit app code and metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get current Snowflake context information\n",
    "        current_database = session.sql(\"SELECT CURRENT_DATABASE()\").collect()[0][0]\n",
    "        current_schema = session.sql(\"SELECT CURRENT_SCHEMA()\").collect()[0][0]\n",
    "        current_warehouse = session.sql(\"SELECT CURRENT_WAREHOUSE()\").collect()[0][0]\n",
    "        current_account = session.sql(\"SELECT CURRENT_ACCOUNT_NAME()\").collect()[0][0]\n",
    "        current_org = session.sql(\"SELECT CURRENT_ORGANIZATION_NAME()\").collect()[0][0]\n",
    "        \n",
    "        # Set variables for use in the procedure\n",
    "        database = current_database\n",
    "        schema = current_schema\n",
    "        warehouse = current_warehouse\n",
    "        account_name = current_account\n",
    "        org_name = current_org\n",
    "        \n",
    "        # Import Snowflake Cortex Complete\n",
    "        from snowflake.cortex import Complete, CompleteOptions\n",
    "\n",
    "        # Create the prompt for generating Streamlit app\n",
    "        system_prompt = \"\"\"You are an expert Python developer specializing in Streamlit applications for data visualization and analysis. \n",
    "        Generate a complete, functional Streamlit application based on the provided content. The app should:\n",
    "        1. Be self-contained and ready to run\n",
    "        2. Include proper imports\n",
    "        3. Have clear structure and comments\n",
    "        4. Include data visualization where appropriate\n",
    "        5. Be user-friendly with proper titles and descriptions\n",
    "        6. Handle errors gracefully\n",
    "        \n",
    "        Return only the Python code for the Streamlit app, no additional text or markdown formatting.\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"Based on the following content, create a Streamlit application:\n",
    "\n",
    "{content}\n",
    "\n",
    "Requirements:\n",
    "- Create an interactive dashboard if the content contains data\n",
    "- Use appropriate Streamlit components (charts, tables, filters, etc.)\n",
    "- Include a clear title and description\n",
    "- Make it visually appealing and user-friendly\n",
    "- Add any necessary data processing or analysis\n",
    "\"\"\"\n",
    "\n",
    "        # Combine system and user prompts for Cortex Complete\n",
    "        full_prompt = f\"{system_prompt}\\n\\nUser Request: {user_prompt}\"\n",
    "\n",
    "        # Call Snowflake Cortex Complete API\n",
    "        # Available models: 'snowflake-arctic', 'llama3-8b', 'claude-4-sonnet', 'reka-flash', 'mistral-large', 'mixtral-8x7b', 'llama2-70b-chat', 'gemma-7b'\n",
    "        response = Complete(\n",
    "            model=model_for_generation,  # Using claude-4-sonnet for high-quality code generation\n",
    "            prompt=full_prompt,\n",
    "            session=session,\n",
    "            options=CompleteOptions(max_tokens=8192),\n",
    "        )\n",
    "\n",
    "        # Extract the generated code\n",
    "        streamlit_code = response\n",
    "\n",
    "        # Strip markdown code markers if they exist\n",
    "        streamlit_code = strip_markdown_code_markers(streamlit_code)\n",
    "\n",
    "        # Generate a unique app name with timestamp\n",
    "        timestamp = session.sql(\"SELECT CURRENT_TIMESTAMP()\").collect()[0][0]\n",
    "        app_name = f\"SI_APP_{timestamp.strftime('%Y%m%d_%H%M%S')}\"\n",
    "        stage_name = f\"SI_STREAMLIT_STAGE\"\n",
    "\n",
    "        # Create Streamlit app in Snowflake\n",
    "        streamlit_app_url = None\n",
    "        streamlit_creation_success = False\n",
    "        streamlit_error = None\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Create a stage for the Streamlit files\n",
    "            create_stage_sql = f\"CREATE STAGE IF NOT EXISTS {stage_name}\"\n",
    "            session.sql(create_stage_sql).collect()\n",
    "\n",
    "            # Upload the generated code to the stage\n",
    "            upload_success = upload_code_to_stage(\n",
    "                session, stage_name, streamlit_code, filename=f\"{app_name}.py\"\n",
    "            )\n",
    "\n",
    "            if upload_success:\n",
    "                # Create the Streamlit app using SQL\n",
    "                create_streamlit_sql = f\"\"\"\n",
    "                CREATE STREAMLIT {app_name}\n",
    "                FROM @{stage_name}\n",
    "                MAIN_FILE = '{app_name}.py'\n",
    "                QUERY_WAREHOUSE = {warehouse}\n",
    "                \"\"\"\n",
    "\n",
    "                # Execute the CREATE STREAMLIT command\n",
    "                session.sql(create_streamlit_sql).collect()\n",
    "\n",
    "                # Construct the Streamlit app URL\n",
    "                streamlit_app_url = f\"https://app.snowflake.com/{org_name}/{account_name}/#/streamlit-apps/{database}.{schema}.{app_name}\"\n",
    "                streamlit_creation_success = True\n",
    "            else:\n",
    "                streamlit_error = \"Failed to upload code to stage\"\n",
    "                streamlit_creation_success = False\n",
    "\n",
    "        except Exception as streamlit_error_obj:\n",
    "            streamlit_error = str(streamlit_error_obj)\n",
    "            streamlit_creation_success = False\n",
    "\n",
    "        # Create response object\n",
    "        result = {\n",
    "            \"success\": True,\n",
    "            \"error\": None,\n",
    "            \"streamlit_code\": streamlit_code,\n",
    "            \"streamlit_app\": {\n",
    "                \"created\": streamlit_creation_success,\n",
    "                \"app_name\": app_name if streamlit_creation_success else None,\n",
    "                \"stage_name\": stage_name if streamlit_creation_success else None,\n",
    "                \"database\": database,\n",
    "                \"schema\": schema,\n",
    "                \"url\": streamlit_app_url,\n",
    "                \"error\": streamlit_error,\n",
    "                \"instructions\": \"If the app was created successfully, you can access it via the URL above or through the Snowflake web interface under Streamlit Apps.\",\n",
    "            },\n",
    "            \"metadata\": {\n",
    "                \"model_used\": \"claude-4-sonnet\",\n",
    "                \"content_length\": len(content),\n",
    "                \"generated_at\": timestamp.isoformat(),\n",
    "                \"prompt_length\": len(full_prompt),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        return json.dumps(result, indent=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return error information\n",
    "        error_result = {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"error_type\": type(e).__name__,\n",
    "            \"streamlit_code\": None,\n",
    "        }\n",
    "        return json.dumps(error_result, indent=2)\n",
    "\n",
    "\n",
    "print('Stored Procedure \"generate_streamlit(varchar) created.\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2654c-0a94-4f08-9834-e659ccaf921c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "test"
   },
   "outputs": [],
   "source": [
    "result_df = session.sql(\n",
    "    \"call generate_streamlit('a simple streamlit app that says hello world')\"\n",
    ").collect()\n",
    "\n",
    "# Extract result from the returned Row\n",
    "# Stored procs in Snowflake return a single column named 'GENERATE_STREAMLIT(...)'\n",
    "result_str = result_df[0][0]\n",
    "\n",
    "# Display it as JSON in Streamlit\n",
    "try:\n",
    "    json_obj = json.loads(result_str)\n",
    "except json.JSONDecodeError:\n",
    "    json_obj = {\"result\": result_str}\n",
    "\n",
    "# Try to extract and show the URL\n",
    "streamlit_url = (\n",
    "    json_obj.get('streamlit_app', {}).get('url')\n",
    "    if isinstance(json_obj, dict)\n",
    "    else None\n",
    ")\n",
    "\n",
    "if streamlit_url:\n",
    "    st.write('Streamlit app URL: ', streamlit_url)\n",
    "else:\n",
    "    st.warning(\"No Streamlit app URL found in result.\")\n",
    "\n",
    "# Show full result\n",
    "st.write(\"Raw JSON Output:\", json_obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "jeff.hollan@snowflake.com",
   "authorId": "5323555631422",
   "authorName": "JEFFHOLLAN",
   "lastEditTime": 1754537181750,
   "notebookId": "tbdsf5anvyms2zp2j2wd",
   "sessionId": "5b4efd38-539e-4833-90dc-6b0535494534"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
